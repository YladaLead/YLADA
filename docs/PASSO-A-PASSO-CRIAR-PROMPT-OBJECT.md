# üìã PASSO A PASSO - Criar Prompt Object LYA na OpenAI Platform

**Guia completo do que voc√™ precisa fazer manualmente**

---

## ‚úÖ O QUE J√Å FOI FEITO (AUTOM√ÅTICO)

- ‚úÖ Template do Prompt Object criado (`docs/TEMPLATE-PROMPT-OBJECT-LYA.md`)
- ‚úÖ Endpoint `/api/nutri/lya/analise-v2` criado (preparado para Responses API)
- ‚úÖ C√≥digo com fallback para chat completions

---

## üéØ O QUE VOC√ä PRECISA FAZER (MANUAL)

### **PASSO 1: Acessar OpenAI Platform**

1. Acesse: https://platform.openai.com
2. Fa√ßa login na sua conta
3. No menu lateral, clique em **"Prompts"** (ou v√° direto: https://platform.openai.com/prompts)

---

### **PASSO 2: Criar Novo Prompt**

1. Clique no bot√£o **"Create prompt"** (ou **"+ New"**)
2. Voc√™ ver√° um formul√°rio para criar o prompt

---

### **PASSO 3: Preencher Informa√ß√µes**

1. **Name (Nome):**
   ```
   LYA ‚Äî Prompt Mestre (Nutri YLADA)
   ```

2. **Description (Descri√ß√£o - opcional):**
   ```
   Prompt mestre da mentora LYA para nutricionistas. Inclui identidade, miss√£o, regras, formato fixo de resposta e l√≥gica de decis√£o.
   ```

3. **Content (Conte√∫do):**
   - Abra o arquivo: `docs/TEMPLATE-PROMPT-OBJECT-LYA.md`
   - Copie TODO o conte√∫do da se√ß√£o "üìù CONTE√öDO DO PROMPT OBJECT"
   - Cole no campo "Content" ou "System/Instructions"

---

### **PASSO 4: Configurar Vari√°veis (Opcional mas Recomendado)**

Se o Dashboard permitir definir vari√°veis, adicione:

- `{{diagnostico}}`
- `{{perfil}}`
- `{{sistema}}`
- `{{rag}}`
- `{{task}}`

**Nota:** Se n√£o houver campo espec√≠fico para vari√°veis, n√£o se preocupe. As vari√°veis podem ser enviadas no c√≥digo mesmo.

---

### **PASSO 5: Configura√ß√µes Avan√ßadas (Opcional)**

Se dispon√≠vel, configure:

- **Model:** `gpt-4o-mini` (ou deixe padr√£o)
- **Temperature:** `0.5` (ou deixe padr√£o)
- **Max tokens:** `700` (ou deixe padr√£o)

**Nota:** Essas configura√ß√µes podem ser sobrescritas no c√≥digo, ent√£o n√£o √© cr√≠tico.

---

### **PASSO 6: Salvar e Publicar**

1. Clique em **"Save"** ou **"Publish"**
2. O Dashboard vai gerar um `prompt_id`
3. **COPIE O `prompt_id`** (formato: `pmpt_...`)
   - Exemplo: `pmpt_abc123xyz...`

---

### **PASSO 7: Adicionar no .env**

1. Abra o arquivo `.env` (ou `.env.local`)
2. Adicione a linha:
   ```
   LYA_PROMPT_ID=pmpt_...
   ```
   (Substitua `pmpt_...` pelo ID real que voc√™ copiou)

3. Salve o arquivo
4. Reinicie o servidor (`npm run dev`)

---

### **PASSO 8: Testar**

1. O endpoint `/api/nutri/lya/analise-v2` j√° est√° pronto
2. Por enquanto, ele usa **fallback** (chat completions)
3. Quando Responses API estiver dispon√≠vel, ele tentar√° usar o Prompt Object automaticamente

**Para testar:**
- Fa√ßa login na √°rea Nutri
- A an√°lise da LYA ser√° gerada normalmente
- Verifique os logs do servidor para ver se est√° usando o `prompt_id`

---

## üîç VERIFICA√á√ÉO

### **Como saber se funcionou:**

1. **No terminal do servidor**, voc√™ deve ver:
   ```
   ü§ñ [LYA v2] Tentando usar Responses API com prompt_id: pmpt_...
   ```
   ou
   ```
   ‚ö†Ô∏è [LYA v2] Responses API n√£o dispon√≠vel, usando fallback
   ```

2. **No console do navegador**, a an√°lise deve aparecer normalmente

3. **No Supabase**, verifique a tabela `ai_memory_events`:
   ```sql
   SELECT * FROM ai_memory_events 
   WHERE user_id = 'seu-user-id'
   ORDER BY created_at DESC
   LIMIT 1;
   ```
   
   Deve mostrar `prompt_id` no campo `conteudo`.

---

## ‚ö†Ô∏è IMPORTANTE

- **Por enquanto:** O sistema usa **fallback** (chat completions) porque Responses API ainda n√£o est√° totalmente dispon√≠vel
- **Quando Responses API estiver dispon√≠vel:** O c√≥digo tentar√° usar automaticamente
- **N√£o quebra nada:** Se Responses API n√£o funcionar, volta para chat completions

---

## üìù PR√ìXIMOS PASSOS (DEPOIS DE CRIAR)

1. ‚úÖ Prompt Object criado
2. ‚úÖ `prompt_id` adicionado no `.env`
3. ‚è≥ Aguardar Responses API estar dispon√≠vel
4. ‚è≥ Testar com Responses API quando dispon√≠vel
5. ‚è≥ Migrar gradualmente (5% ‚Üí 25% ‚Üí 100%)

---

## üÜò SE DER ERRO

**Erro: "Responses API n√£o dispon√≠vel"**
- ‚úÖ Normal! Por enquanto usa fallback
- ‚úÖ Sistema continua funcionando normalmente

**Erro: "prompt_id n√£o encontrado"**
- Verifique se o `prompt_id` est√° correto no `.env`
- Verifique se o Prompt Object foi publicado no Dashboard

**Erro: "Vari√°veis n√£o encontradas"**
- Normal, vari√°veis s√£o enviadas no c√≥digo
- N√£o precisa configurar no Dashboard

---

## ‚úÖ RESUMO

1. ‚úÖ Acessar OpenAI Platform ‚Üí Prompts
2. ‚úÖ Criar novo prompt
3. ‚úÖ Colar template do `TEMPLATE-PROMPT-OBJECT-LYA.md`
4. ‚úÖ Salvar e copiar `prompt_id`
5. ‚úÖ Adicionar `LYA_PROMPT_ID=pmpt_...` no `.env`
6. ‚úÖ Reiniciar servidor
7. ‚úÖ Testar (vai usar fallback por enquanto)

**Pronto! O sistema est√° preparado para Responses API quando estiver dispon√≠vel.**

